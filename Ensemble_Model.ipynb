{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d99121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da472449",
   "metadata": {},
   "source": [
    "# 1. read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c895146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutated_sequence(mut, sequence_wt):\n",
    "  wt, pos, mt = mut[0], int(mut[1:-1]), mut[-1]\n",
    "\n",
    "  sequence = deepcopy(sequence_wt)\n",
    "\n",
    "  return sequence[:pos]+mt+sequence[pos+1:]\n",
    "\n",
    "def get_pos_sequence(mut):\n",
    "  wt, pos, mt = mut[0], int(mut[1:-1]), mut[-1]\n",
    "\n",
    "  return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8149d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hackathon_data/sequence.fasta', 'r') as f:\n",
    "  data = f.readlines()\n",
    "\n",
    "sequence_wt = data[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2a18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "# read in all train data\n",
    "df_base = pd.read_csv('Hackathon_data/train.csv')\n",
    "df_base['mut_seq'] = df_base.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_base['pos'] = df_base.mutant.apply(lambda x: get_pos_sequence(x))\n",
    "df_base['wt_seq'] = sequence_wt\n",
    "df_base.loc[:, \"score\"] = df_base[\"DMS_score\"]\n",
    "\n",
    "df_train2 = pd.read_csv('Hackathon_data/train2.csv')\n",
    "df_train2['mut_seq'] = df_train2.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train2['pos'] = df_train2.mutant.apply(lambda x: get_pos_sequence(x))\n",
    "df_train2['wt_seq'] = sequence_wt\n",
    "df_train2.loc[:, \"score\"] = df_train2[\"DMS_score\"]\n",
    "\n",
    "df_train3 = pd.read_csv('Hackathon_data/train3.csv')\n",
    "df_train3['mut_seq'] = df_train3.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train3['pos'] = df_train3.mutant.apply(lambda x: get_pos_sequence(x))\n",
    "df_train3['wt_seq'] = sequence_wt\n",
    "df_train3.loc[:, \"score\"] = df_train3[\"DMS_score\"]\n",
    "\n",
    "df_train4 = pd.read_csv('Hackathon_data/train4.csv')\n",
    "df_train4['mut_seq'] = df_train4.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train4['pos'] = df_train4.mutant.apply(lambda x: get_pos_sequence(x))\n",
    "df_train4['wt_seq'] = sequence_wt\n",
    "df_train4.loc[:, \"score\"] = df_train4[\"DMS_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ec01b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>DMS_score</th>\n",
       "      <th>mut_seq</th>\n",
       "      <th>pos</th>\n",
       "      <th>wt_seq</th>\n",
       "      <th>score</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0Y</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0W</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0V</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0T</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0S</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>F581E</td>\n",
       "      <td>0.855451</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>581</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.855451</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>A586P</td>\n",
       "      <td>0.989355</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>586</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.989355</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>R593P</td>\n",
       "      <td>0.806492</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>593</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.806492</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>N619I</td>\n",
       "      <td>0.911438</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>619</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.911438</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>V634P</td>\n",
       "      <td>0.569993</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>634</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>0.569993</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mutant  DMS_score                                            mut_seq  \\\n",
       "0       M0Y   0.273000  YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1       M0W   0.285700  WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "2       M0V   0.215300  VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "3       M0T   0.312200  TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "4       M0S   0.218000  SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "...     ...        ...                                                ...   \n",
       "1435  F581E   0.855451  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1436  A586P   0.989355  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1437  R593P   0.806492  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1438  N619I   0.911438  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1439  V634P   0.569993  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "\n",
       "      pos                                             wt_seq     score  \\\n",
       "0       0  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.273000   \n",
       "1       0  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.285700   \n",
       "2       0  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.215300   \n",
       "3       0  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.312200   \n",
       "4       0  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.218000   \n",
       "...   ...                                                ...       ...   \n",
       "1435  581  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.855451   \n",
       "1436  586  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.989355   \n",
       "1437  593  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.806492   \n",
       "1438  619  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.911438   \n",
       "1439  634  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  0.569993   \n",
       "\n",
       "                                               sequence  \n",
       "0                                                   NaN  \n",
       "1                                                   NaN  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "1435  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  \n",
       "1436  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  \n",
       "1437  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  \n",
       "1438  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  \n",
       "1439  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...  \n",
       "\n",
       "[1440 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine initial train data and query data\n",
    "df_train = pd.concat([df_base, df_train2, df_train3, df_train4], ignore_index=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764cd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test data\n",
    "df_test = pd.read_csv('Hackathon_data/test.csv')\n",
    "df_test['mut_seq'] = df_test.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_test['pos'] = df_test.mutant.apply(lambda x: get_pos_sequence(x))\n",
    "df_test['wt_seq'] = sequence_wt\n",
    "df_test.loc[:, \"score\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3efec",
   "metadata": {},
   "source": [
    "# 2. Get AA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63fbe571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 566 AAindex records.\n"
     ]
    }
   ],
   "source": [
    "from aaindex import aaindex1\n",
    "\n",
    "# Get all 20 standard amino acids\n",
    "aa_list = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "# Collect all usable AAindex1 codes (those with all 20 AAs)\n",
    "record_codes = [\n",
    "    code for code in aaindex1.record_codes()\n",
    "    if all(aa in aaindex1[code].values for aa in aa_list)\n",
    "]\n",
    "\n",
    "print(f\"Using {len(record_codes)} AAindex records.\")\n",
    "\n",
    "# Build the embedding matrix: 20 AA Ã— N features\n",
    "aa_matrix = np.array([\n",
    "    [aaindex1[code].values[aa] for code in record_codes]\n",
    "    for aa in aa_list\n",
    "], dtype=np.float32)  # shape: (20, num_records)\n",
    "\n",
    "# normalize across features (z-score normalization)\n",
    "aa_matrix = (aa_matrix - aa_matrix.mean(axis=0)) / aa_matrix.std(axis=0)\n",
    "\n",
    "# Build the final embedding dictionary\n",
    "aaindex_dict = {\n",
    "    aa: aa_matrix[i].tolist()\n",
    "    for i, aa in enumerate(aa_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad831d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AA_embeddings(mut_str, aaindex_dict, length=656):\n",
    "    ref_aa = mut_str[0]\n",
    "    mut_aa = mut_str[-1]\n",
    "    pos = int(mut_str[1:-1])\n",
    "\n",
    "    ref_emb = np.array(aaindex_dict.get(ref_aa))\n",
    "    mut_emb = np.array(aaindex_dict.get(mut_aa))\n",
    "\n",
    "    position = pos / length\n",
    "    region = np.zeros(5)\n",
    "    region_idx = min(pos * 5 // length, 4)  # ensure index stays in 0-4\n",
    "    region[region_idx] = 1.0\n",
    "\n",
    "\n",
    "\n",
    "    full_feature = np.concatenate([\n",
    "        mut_emb - ref_emb, [position], region\n",
    "    ])\n",
    "    return full_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59de8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form AA feature matrix for train data\n",
    "features = df_train.apply(\n",
    "    lambda row: get_AA_embeddings(row['mutant'], aaindex_dict),\n",
    "    axis=1\n",
    ")\n",
    "XAA = np.stack(features.values)\n",
    "y = df_train['DMS_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0d30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form AA feature matrix for test data\n",
    "features_test = df_test.apply(\n",
    "    lambda row: get_AA_embeddings(row['mutant'], aaindex_dict),\n",
    "    axis=1\n",
    ")\n",
    "X_test = np.stack(features_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b9568",
   "metadata": {},
   "source": [
    "# 3 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a50ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, RationalQuadratic, ExpSineSquared, WhiteKernel\n",
    "def spearman_scorer(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred).correlation\n",
    "custom_scorer = make_scorer(spearman_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d92010",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Ridge':Ridge(),\n",
    "    'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(random_state=42),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge':{\n",
    "        'alpha': [0.01, 0.1, 1.0, 10.0, 100]\n",
    "    },\n",
    "    'GradientBoostingRegressor':{\n",
    "        'n_estimators':[50, 100, 200],\n",
    "        'max_depth':[3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'subsample':[0.8, 1.0]\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, None],\n",
    "        'min_samples_leaf': [1, 5, 10],\n",
    "        'min_samples_split': [2, 10, 20],\n",
    "        'bootstrap': [True, False],\n",
    "    },\n",
    "    'KNN':{\n",
    "        'n_neighbors':[5,10],\n",
    "        'weights':['uniform', 'distance'],\n",
    "        'algorithm':['ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size':[15, 30],\n",
    "        'p':[1,2]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.1, 0.5, 1.0, 10],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'epsilon': [0.05, 0.1, 0.2],\n",
    "        'kernel': ['rbf', 'linear', 'poly']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6bb84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Grid Search: RIDGE ---\n",
      "{'alpha': 1.0}\n",
      "Fold 1: Spearman = 0.4385\n",
      "Fold 2: Spearman = 0.4552\n",
      "Fold 3: Spearman = 0.3862\n",
      "Fold 4: Spearman = 0.2931\n",
      "Fold 5: Spearman = 0.3278\n",
      "Avg Spearman: 0.3801 Â± 0.0623\n",
      "\n",
      "--- Grid Search: GRADIENTBOOSTINGREGRESSOR ---\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Fold 1: Spearman = 0.5388\n",
      "Fold 2: Spearman = 0.5889\n",
      "Fold 3: Spearman = 0.4792\n",
      "Fold 4: Spearman = 0.3762\n",
      "Fold 5: Spearman = 0.4192\n",
      "Avg Spearman: 0.4805 Â± 0.0772\n",
      "\n",
      "--- Grid Search: XGBREGRESSOR ---\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.7}\n",
      "Fold 1: Spearman = 0.5384\n",
      "Fold 2: Spearman = 0.6023\n",
      "Fold 3: Spearman = 0.5118\n",
      "Fold 4: Spearman = 0.4695\n",
      "Fold 5: Spearman = 0.4226\n",
      "Avg Spearman: 0.5089 Â± 0.0610\n",
      "\n",
      "--- Grid Search: RANDOMFORESTREGRESSOR ---\n",
      "{'bootstrap': True, 'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Fold 1: Spearman = 0.5360\n",
      "Fold 2: Spearman = 0.6096\n",
      "Fold 3: Spearman = 0.4945\n",
      "Fold 4: Spearman = 0.4162\n",
      "Fold 5: Spearman = 0.3978\n",
      "Avg Spearman: 0.4908 Â± 0.0780\n",
      "\n",
      "--- Grid Search: KNN ---\n",
      "{'algorithm': 'ball_tree', 'leaf_size': 15, 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
      "Fold 1: Spearman = 0.3032\n",
      "Fold 2: Spearman = 0.2691\n",
      "Fold 3: Spearman = 0.3763\n",
      "Fold 4: Spearman = 0.1776\n",
      "Fold 5: Spearman = 0.2086\n",
      "Avg Spearman: 0.2670 Â± 0.0702\n",
      "\n",
      "--- Grid Search: SVR ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Performa grid search for a list of models\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "group = df_train['pos']\n",
    "\n",
    "# --- Main loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Grid Search: {model_name.upper()} ---\")\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        estimator = model,\n",
    "        param_grid= param_grids[model_name],\n",
    "        scoring= custom_scorer,\n",
    "        cv=gkf,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    grid.fit(XAA, y, groups = group)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    print(best_params)\n",
    "    \n",
    "    spearman_scores = []\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(XAA, y, groups=df_train['pos'])):\n",
    "        X_train, X_val = XAA[train_idx], XAA[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Train & predict\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_val)\n",
    "\n",
    "        # Spearman correlation\n",
    "        corr, _ = spearmanr(y_val, y_pred)\n",
    "        spearman_scores.append(corr)\n",
    "        print(f\"Fold {fold + 1}: Spearman = {corr:.4f}\")\n",
    "\n",
    "    # Final results\n",
    "    avg_corr = np.mean(spearman_scores)\n",
    "    std_corr = np.std(spearman_scores)\n",
    "    print(f\"Avg Spearman: {avg_corr:.4f} Â± {std_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d53d87",
   "metadata": {},
   "source": [
    "# Train Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a set of model based on grid search (some modification was made later after adding regularization parameters)\n",
    "model1 = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "model2 =  XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.01,                         \n",
    "            reg_lambda=1.0,             \n",
    "            reg_alpha=0.0, \n",
    "            subsample=0.8,\n",
    "            n_jobs=-1,\n",
    "            random_state = 1\n",
    ")\n",
    "\n",
    "model3 = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=20,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "model4 = SVR(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    epsilon=0.1,\n",
    "    C=0.5,\n",
    ")\n",
    "emsembled_models = [model1, model2, model3, model4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "253e67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ensemble model\n",
    "trained_models = []\n",
    "\n",
    "for i, model in enumerate(emsembled_models):\n",
    "\n",
    "    model.fit(XAA, y)\n",
    "    y_pred = model.predict(XAA)\n",
    "    spearman_corr, _ = spearmanr(y, y_pred)\n",
    "    trained_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d5c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on test set\n",
    "preds = []\n",
    "\n",
    "for i, model in enumerate(trained_models):\n",
    "    pred = model.predict(X_test)\n",
    "    preds.append(pred)\n",
    "    \n",
    "preds = np.stack(preds, axis=0)\n",
    "preds_mean = np.mean(preds, axis=0)\n",
    "df_test['DMS_score_predicted'] = preds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c741c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output prediction results\n",
    "df_test[['mutant', 'DMS_score_predicted']].to_csv('Ensemble_Model_Predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23634afd",
   "metadata": {},
   "source": [
    "# (Optional) Make new queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_std = np.std(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use uncertainty sampling for new queries\n",
    "top100_indices = np.argsort(preds_std)[-100:]\n",
    "mutants = [df_test.iloc[i]['mutant'] for i in topk_indices]\n",
    "\n",
    "# Write to a .txt file\n",
    "with open('query.txt', 'w') as f:\n",
    "    for mutant in mutants:\n",
    "        f.write(mutant+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9(torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
